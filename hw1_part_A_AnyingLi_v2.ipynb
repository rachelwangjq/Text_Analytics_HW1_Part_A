{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranjor/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import operator\n",
    "import re,string\n",
    "from patsy import dmatrices\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1. What are the top 5 parts of speech in this corpus of job descriptions? How frequently do they appear?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) import file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                             Title  \\\n",
       "0  12612628       Engineering Systems Analyst   \n",
       "1  12612830           Stress Engineer Glasgow   \n",
       "2  12612844  Modelling and simulation analyst   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractType  \\\n",
       "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "2  Hampshire, South East, South East          Hampshire          NaN   \n",
       "\n",
       "  ContractTime                       Company          Category  \\\n",
       "0    permanent  Gregory Martin International  Engineering Jobs   \n",
       "1    permanent  Gregory Martin International  Engineering Jobs   \n",
       "2    permanent  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "                    SalaryRaw  SalaryNormalized        SourceName  \n",
       "0  20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
       "1  25000 - 35000/annum 25-35K             30000  cv-library.co.uk  \n",
       "2  20000 - 40000/annum 20-40K             30000  cv-library.co.uk  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('/Users/pranjor/Documents/UT/MSBA/Text Analytics/project 1/Train_rev1.csv')\n",
    "\n",
    "train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) tokenize the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "description  = train['FullDescription'][:1000]\n",
    "\n",
    "corpus = description.str.cat(sep=' ')\n",
    "\n",
    "corpus = corpus.decode('utf-8')\n",
    "\n",
    "corpus_words = nltk.word_tokenize(corpus.lower())",
    "\n",
    "corpus_words = [word for word in corpus_words if word.isalpha()==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Calculate the frequencies of PoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'engineering', 'NN'),\n",
       " (u'systems', 'NNS'),\n",
       " (u'analyst', 'NN'),\n",
       " (u'dorking', 'VBG'),\n",
       " (u'surrey', 'JJ'),\n",
       " (u'salary', 'JJ'),\n",
       " (u'k', 'VB'),\n",
       " (u'our', 'PRP$'),\n",
       " (u'client', 'NN'),\n",
       " (u'is', 'VBZ')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = nltk.pos_tag(corpus_words)\n",
    "\n",
    "pos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranjor/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>54170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JJ</th>\n",
       "      <td>23215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>22997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>17179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNS</th>\n",
       "      <td>15575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word\n",
       "pos       \n",
       "NN   54170\n",
       "JJ   23215\n",
       "IN   22997\n",
       "DT   17179\n",
       "NNS  15575"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_freq = sorted(pos, key=lambda x: x[1],reverse=True)\n",
    "\n",
    "df_pos = pd.DataFrame(pos_freq)\n",
    "\n",
    "\n",
    "df_pos.columns = ['word','pos']\n",
    "\n",
    "df_pos.groupby('pos').count().sort('word',ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2. Does this corpus support Zipfâ€™s law? Plot the most common 100 words in the corpus against the theoretical prediction of the law."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Calculate the frequencies of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(corpus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>8436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.</td>\n",
       "      <td>8005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>7121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td>6932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>6677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>5813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>of</td>\n",
       "      <td>4547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>4229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>for</td>\n",
       "      <td>3450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>care</td>\n",
       "      <td>3033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  freq\n",
       "0   and  8436\n",
       "1     .  8005\n",
       "2   the  7121\n",
       "3     ,  6932\n",
       "4    to  6677\n",
       "5     a  5813\n",
       "6    of  4547\n",
       "7    in  4229\n",
       "8   for  3450\n",
       "9  care  3033"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_sorted = sorted(fdist.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "df = pd.DataFrame.from_records(c_sorted)\n",
    "df.columns = ['word','freq']\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Get rid of the punctuation marks and then rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = ~df['word'].isin(set(string.punctuation)) \n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "df['rank'] = df['freq'].rank(method='min',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>8436</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>7121</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>6677</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>5813</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>of</td>\n",
       "      <td>4547</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  freq  rank\n",
       "0  and  8436   1.0\n",
       "2  the  7121   2.0\n",
       "4   to  6677   3.0\n",
       "5    a  5813   4.0\n",
       "6   of  4547   5.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5][['word','freq','rank']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Plot the most common 100 words in the corpus against the theoretical prediction of the law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fd19450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['x^-1']= [c**-1 for c in df['rank']]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = plt.plot([math.log(c) for c in df['rank'].values], [math.log(c) for c in df['freq']], 'ro',color='black')\n",
    "\n",
    "ax2 = plt.plot([math.log(c) for c in df['rank'].values], [math.log(c) for c in df['x^-1']], 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3. If we remove stopwords and lemmatize the corpus, what are the 10 most common words? What is their frequency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'care', 3060),\n",
       " (u'home', 2117),\n",
       " (u'experience', 1366),\n",
       " (u'manager', 1276),\n",
       " (u'nurse', 1266),\n",
       " (u'work', 1201),\n",
       " (u'nursing', 1180),\n",
       " (u'support', 1093),\n",
       " (u'within', 1040),\n",
       " (u'working', 965)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "corpus_words= [word for word in corpus_words if word not in set(string.punctuation)]\n",
    "\n",
    "filtered_words_sw = [word for word in corpus_words if word not in stopwords.words('english')]\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "words_lem = [wnl.lemmatize(word) for word in filtered_words_sw]\n",
    "\n",
    "fdist_2 = nltk.FreqDist(words_lem)\n",
    "fdist_2.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## B1 Create a classification model with all words and the bag-of-words approach. How accurate is the model (show the confusion matrix)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a function that counts the frequency of each token in a document\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in corpus_words:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find the cutoff salary\n",
    "cutoff = np.percentile(train[['SalaryNormalized']], 75)\n",
    "train['category'] = 'high'\n",
    "train.ix[train.SalaryNormalized < cutoff, 'category'] = 'low'\n",
    "\n",
    "train['token'] = \"\"\n",
    "fullset = train[['FullDescription','token','category']][:1000]\n",
    "\n",
    "#calculate the document_features in each document\n",
    "from __future__ import unicode_literals\n",
    "for i in range(len(fullset)):\n",
    "    words = re.sub(r'[^\\w\\s]','',fullset.FullDescription[i])\n",
    "    token = nltk.word_tokenize(words.lower().decode('utf-8'))\n",
    "    feature = document_features(token)\n",
    "    fullset.token[i] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fullset['feature_sets'] = zip(fullset.token, fullset.category)\n",
    "featuresets = fullset.feature_sets.tolist()\n",
    "train_set, test_set = featuresets[:500], featuresets[500:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is  0.814\n"
     ]
    }
   ],
   "source": [
    "print 'the accuracy is ', nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B2 . Speculate before running the following analysis whether lemmatization would help improve the accuracy of classification. Now create a classification model after lemmatization. Did the classification accuracy increase relative to B1? Comment on your speculation versus the actual results you obtained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lemmtization should improve the accuracy since there will be fewer tokens. With each token appearing in a document, the likelihood of the document being positive or negative will increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(fullset)):\n",
    "    words = re.sub(r'[^\\w\\s]','',fullset.FullDescription[i])\n",
    "    token = nltk.word_tokenize(words.lower().decode('utf-8'))\n",
    "    lemma = [wnl.lemmatize(word) for word in token]\n",
    "    feature = document_features(lemma)\n",
    "    fullset.token[i] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fullset['feature_sets'] = zip(fullset.token, fullset.category)\n",
    "featuresets = fullset.feature_sets.tolist()\n",
    "train_set, test_set = featuresets[:500], featuresets[500:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is  0.812\n"
     ]
    }
   ],
   "source": [
    "print 'the accuracy is ', nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After lemmatization, the accuracy actually went down from 0.814 to 0.812. Perhaps it's because the lemmatized words have more similar likelihood in both high and low salary categories than the pre-lemmatized words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B4 .  Use the job descriptions without lemmatiztion and stopword removal. Add parts-of-speech bigrams to the bag-of-words, and run a new classification model. Does the accuracy increase over the results in B1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_pos = [tag for (word,tag) in pos]\n",
    "corpus_pos_bigram = list(nltk.bigrams(corpus_pos))\n",
    "corpus_combined = corpus_words+corpus_pos_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a function that counts the frequency of each token in a document\n",
    "def document_features_bigram(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in corpus_combined:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(fullset)):\n",
    "    words = re.sub(r'[^\\w\\s]','',fullset.FullDescription[i])\n",
    "    token = nltk.word_tokenize(words.lower().decode('utf-8'))\n",
    "    pos_tag = nltk.pos_tag(token)\n",
    "    pos_only = [tag for (word,tag) in pos_tag]\n",
    "    bigram = list(nltk.bigrams(pos))\n",
    "    combine = token + bigram\n",
    "    feature = document_features_bigram(combine)\n",
    "    fullset.token[i] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fullset['feature_sets'] = zip(fullset.token, fullset.category)\n",
    "featuresets = fullset.feature_sets.tolist()\n",
    "train_set, test_set = featuresets[:500], featuresets[500:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is  0.814\n"
     ]
    }
   ],
   "source": [
    "print 'the accuracy is ', nltk.classify.accuracy(classifier, test_set)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
